{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 31 iterations.\n",
      "Optimal point: [-0.16429752  1.0392607  -0.43213083]\n",
      "Optimal function value: -2.9267857130752235\n",
      "Gradient norm at optimal point: 8.026835421817195e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def f(x):\n",
    "    x1, x2, x3 = x\n",
    "    return 4 * x1**2 + 3 * x2**2 + 5 * x3**2 - 3 * x1 * x2 + 4 * x2 * x3 - x1 * x3 + 4 * x1 - 5 * x2\n",
    "\n",
    "\n",
    "def grad_f(x):\n",
    "    x1, x2, x3 = x\n",
    "    df_dx1 = 8 * x1 - 3 * x2 - x3 + 4\n",
    "    df_dx2 = -3 * x1 + 6 * x2 + 4 * x3 - 5\n",
    "    df_dx3 = 10 * x3 + 4 * x2 - x1\n",
    "    return np.array([df_dx1, df_dx2, df_dx3])\n",
    "\n",
    "\n",
    "r = 8  # Last digit of my roll number (B21CS098)\n",
    "x0 = np.array([2 + r / 10, 3 - r / 10, 6])  # Initial point\n",
    "tol = 1e-4  # Tolerance for stopping criteria ( given in the question)\n",
    "max_iter = 1000  # Maximum number of iterations (I am assuming this)\n",
    "alpha = 1e-1  # Initial step size for line search\n",
    "\n",
    "\n",
    "x = x0\n",
    "for i in range(max_iter):\n",
    "    gradient = grad_f(x)\n",
    "    grad_norm = np.linalg.norm(gradient)\n",
    "    if grad_norm < tol:\n",
    "        print(f\"Converged in {i} iterations.\")\n",
    "        break\n",
    "    t = alpha\n",
    "    beta = 0.5  \n",
    "    c = 1e-4  \n",
    "    while f(x - t * gradient) > f(x) - c * t * grad_norm**2:\n",
    "        t *= beta\n",
    "    x = x - t * gradient\n",
    "\n",
    "\n",
    "print(\"Optimal point:\", x)\n",
    "print(\"Optimal function value:\", f(x))\n",
    "print(\"Gradient norm at optimal point:\", grad_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha is: [ 635.04255665 -998.52      ]\n",
      "Objective function value is: 670425076.6550275\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"multiple_linear_regression_dataset - Copy (1).csv\")\n",
    "X = data[['age', 'experience']].values\n",
    "y = data['Income'].values\n",
    "R = 98  # R=B21CS098 ( As 98 is my last digit of the rollNumber)\n",
    "lambda_reg = abs(R) / 100 - 0.5  \n",
    "alpha = np.array([1.0, 1.0]) \n",
    "tol = 1e-4 \n",
    "max_iter = 1000  \n",
    "learning_rate = 0.001  \n",
    "\n",
    "def model(x, alpha):\n",
    "    return alpha[0] * x[:, 0] + np.exp(np.clip(alpha[1] * x[:, 1], -50, 50))\n",
    "\n",
    "def objective(alpha, X, y, lambda_reg):\n",
    "    predictions = model(X, alpha)\n",
    "    mse = np.mean((y - predictions) ** 2)\n",
    "    l1_norm = lambda_reg * np.sum(np.abs(alpha))\n",
    "    return mse + l1_norm\n",
    "\n",
    "def gradient(alpha, X, y):\n",
    "    predictions = model(X, alpha)\n",
    "    error = predictions - y\n",
    "    grad_alpha1 = np.mean(2 * error * X[:, 0])\n",
    "    grad_alpha2 = np.mean(2 * error * np.exp(np.clip(alpha[1] * X[:, 1], -50, 50)) * X[:, 1])\n",
    "    grad_alpha1 = np.clip(grad_alpha1, -1e6, 1e6)\n",
    "    grad_alpha2 = np.clip(grad_alpha2, -1e6, 1e6)\n",
    "    return np.array([grad_alpha1, grad_alpha2])\n",
    "\n",
    "\n",
    "def proximal_operator(alpha, learning_rate, lambda_reg):\n",
    "    return np.sign(alpha) * np.maximum(0, np.abs(alpha) - learning_rate * lambda_reg)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    grad = gradient(alpha, X, y)\n",
    "    alpha = alpha - learning_rate * grad  \n",
    "    alpha = proximal_operator(alpha, learning_rate, lambda_reg)  \n",
    "    if np.linalg.norm(grad) < tol:\n",
    "        print(f\"Converged in {i} iterations.\")\n",
    "        break\n",
    "\n",
    "print(\"Optimal alpha is:\", alpha)\n",
    "print(\"Objective function value is:\", objective(alpha, X, y, lambda_reg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omllabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
